{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Math 450 Notebook 10 (Validation).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNNJ5qlqPr0RlKmvdmCRKfa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ffb571b5191d444ea9b93e1fd6b490b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_525a94290a9d4d41948436102b09971d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5793aba684c8441ea3d8dd0cce68fbd7",
              "IPY_MODEL_99e9c0dfa61a496dbb9bfa419377fc71"
            ]
          }
        },
        "525a94290a9d4d41948436102b09971d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5793aba684c8441ea3d8dd0cce68fbd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ab9a55949426491cb3c411b27d356e73",
            "_dom_classes": [],
            "description": "epoch: [1/2] loss: 7.5103accuracy on validation: 0.1642: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 250,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 250,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_50625b8a8ce149af9ba3a3b9533d219b"
          }
        },
        "99e9c0dfa61a496dbb9bfa419377fc71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_beafa0fdd6264ae485dfd8c4362fa995",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 250/250 [00:16&lt;00:00, 11.44it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_647056a0b1c14d029952c14a8f5cd1c2"
          }
        },
        "ab9a55949426491cb3c411b27d356e73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "50625b8a8ce149af9ba3a3b9533d219b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "beafa0fdd6264ae485dfd8c4362fa995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "647056a0b1c14d029952c14a8f5cd1c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scaomath/wustl-math450/blob/main/Lectures/Math_450_Notebook_10_(Validation).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWgIuaGfIBj2"
      },
      "source": [
        "# Coding lecture 10 of Math 450\n",
        "\n",
        "## Last couple of weeks\n",
        "- A complete pipeline of training a machine learning model\n",
        "\n",
        "## Today\n",
        "- How to build a bigger and more complex neural network.\n",
        "- Set up a validation strategy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9wNb-1mJ94C"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.optim import Optimizer\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style(\"dark\")\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPSmTtOBKGiu"
      },
      "source": [
        "train = datasets.MNIST(root='./', \n",
        "                       train=True, \n",
        "                       download=True, \n",
        "                       transform = transforms.ToTensor());\n",
        "\n",
        "train_loader = DataLoader(train, batch_size=8) \n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_size: int = 28*28,\n",
        "                 output_size: int = 10):\n",
        "        super(MLP, self).__init__() \n",
        "        self.linear0 = nn.Linear(input_size, 256)\n",
        "        self.activation = nn.ReLU()\n",
        "        self.linear1 = nn.Linear(256, output_size)\n",
        "        self.dropout = nn.Dropout(0.1) \n",
        "        # 10% of the weight does not get updated: dropout\n",
        "        \n",
        "    def forward(self, x): \n",
        "        x = x.view(x.size(0), -1) \n",
        "        x1 = self.linear0(x)\n",
        "        a1 = self.activation(x1)\n",
        "        output = self.linear1(a1)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikMGFZJgKYYP"
      },
      "source": [
        "class SGD(Optimizer): # subclass of Optimizer\n",
        "    \"\"\"\n",
        "    Implements the vanilla SGD simplified \n",
        "    from the torch official one for Math 450 WashU\n",
        "    \n",
        "    Args:\n",
        "        params (iterable): iterable of parameters to optimize or dicts defining\n",
        "            parameter groups\n",
        "        lr (float): learning rate\n",
        "        \n",
        "    Example:\n",
        "        >>> optimizer = SGD(model.parameters(), lr=1e-2)\n",
        "        >>> optimizer.zero_grad()\n",
        "        >>> loss_fn(model(input), target).backward()\n",
        "        >>> optimizer.step()\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, params, # params: model.parameters()\n",
        "                       lr: float = 1e-3, # input: type = value\n",
        "                 ): \n",
        "        defaults = dict(lr=lr) \n",
        "        # add a default attribute that can be accessed\n",
        "        super(SGD, self).__init__(params, defaults)\n",
        "\n",
        "    def step(self, closure=None): \n",
        "      '''\n",
        "      step(): w_{k+1} = w_k - alpha*grad f(w_k)\n",
        "      '''  \n",
        "      for group in self.param_groups:\n",
        "          for param in group['params']:\n",
        "              if param.grad is None:\n",
        "                  continue\n",
        "              grad_param = param.grad.data\n",
        "              \n",
        "              param.data = param.data - group['lr']*grad_param\n",
        "      return loss"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3j055o9KtP2"
      },
      "source": [
        "model = MLP() # initialize the model\n",
        "loss_func = nn.CrossEntropyLoss() # set up the loss\n",
        "# crossentropyloss is for the case of a balanced classification problem\n",
        "epochs = 2\n",
        "learning_rate = 1e-3\n",
        "optimizer = SGD(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6mqHyFIL24D"
      },
      "source": [
        "# How to build a bigger net?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-WInCW1QDT6"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_size: int = 28*28,\n",
        "                 output_size: int = 10):\n",
        "        super(MLP, self).__init__() \n",
        "        self.linear0 = nn.Linear(input_size, 256)\n",
        "        self.linear1 = nn.Linear(256, 128)\n",
        "        self.linear2 = nn.Linear(128, 64)\n",
        "        self.linear3 = nn.Linear(64, output_size)\n",
        "        self.activation = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.1) \n",
        "        # 10% of the weight does not get updated: dropout\n",
        "        \n",
        "    def forward(self, x): \n",
        "        x = x.view(x.size(0), -1) \n",
        "        x1 = self.linear0(x) # for linear layer, we have to use different names\n",
        "        a1 = self.activation(x1) # activation we can just define a single obj\n",
        "        x2 = self.linear1(a1)\n",
        "        a2 = self.activation(x2)\n",
        "        x3 = self.linear2(a2)\n",
        "        a3 = self.activation(x3)\n",
        "        output = self.linear3(a3)\n",
        "\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0XvrldwRDw3"
      },
      "source": [
        "# `nn.Modulelist`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODtsjM26RAvr"
      },
      "source": [
        "# list\n",
        "lst = []\n",
        "print(lst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjTnu8UxRIyB"
      },
      "source": [
        "lst.append('math450')\n",
        "print(lst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQMfGhA4ROMp"
      },
      "source": [
        "lst.append(10.2)\n",
        "print(lst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oU_UoxtRTm-"
      },
      "source": [
        "lst1 = ['math 450 student ' + str(i) for i in range(5)]\n",
        "print(lst1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaZm8Ya5RhD7"
      },
      "source": [
        "# if we just wanna copy something n times\n",
        "x = np.array([10, 20, -5])\n",
        "print(x.repeat(5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Y6Piw_sR38n"
      },
      "source": [
        "np.vstack([x, x, x, x, x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgIJcz_KSGIF"
      },
      "source": [
        "[x for _ in range(5)] # makes 5 copies of x\n",
        "# but this is a list of arrays"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziLJeM03SUDP"
      },
      "source": [
        "np.asarray([x for _ in range(5)]) \n",
        "# convert the input as an array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yB243_WGSna8"
      },
      "source": [
        "## what is `nn.Modulelist()`?\n",
        "It has operations like list, but it is for `nn` modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xczs0aOCSkui"
      },
      "source": [
        "layers = nn.ModuleList()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hO3WrrDS442"
      },
      "source": [
        "layers # no weight associated with this \"layers\" module"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PFH8Pz5S77O"
      },
      "source": [
        "layers.append(nn.Linear(128, 64))\n",
        "print(layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73R_zcoTTO3c"
      },
      "source": [
        "layers.append(nn.SiLU()) # Swish activation\n",
        "print(layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bQRG4VNTgrs"
      },
      "source": [
        "# access this modulelist using indices\n",
        "print(layers[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHRoIYC3T5ar"
      },
      "source": [
        "layer.parameters()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_xA9KxwTrJq"
      },
      "source": [
        "# this is an iterable\n",
        "for layer in layers:\n",
        "  for param in layer.parameters():\n",
        "    print(param.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBmKM8NMUhhB"
      },
      "source": [
        "['hahaha' for _ in range(10)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u69TK_1bUUsB"
      },
      "source": [
        "layers = nn.ModuleList([nn.Linear(20, 20) for _ in range(10)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6eRkP-TUnwx"
      },
      "source": [
        "layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5bo-je-UsMY"
      },
      "source": [
        "block = nn.Sequential(\n",
        "    nn.Linear(20, 20),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20,20)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeObzAQLU3lQ"
      },
      "source": [
        "block"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryw3CS4MU7Tm"
      },
      "source": [
        "bigger_block = nn.ModuleList([block for _ in range(5)])\n",
        "\n",
        "print(bigger_block)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWRViCK1VK_5"
      },
      "source": [
        "## advanced: memory allocation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtr9D6boVVwu"
      },
      "source": [
        "# standard practice\n",
        "from copy import deepcopy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAuNE5QYVa7C"
      },
      "source": [
        "blocks = nn.ModuleList([deepcopy(block) for _ in range(5)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUq0f1oqVluG"
      },
      "source": [
        "print(blocks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaRH0oAMWApX"
      },
      "source": [
        "# how to add tuples\n",
        "(10, 10) + (80, )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-ArYPaMVpNK"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_size: int = 28*28,\n",
        "                 hidden_size: tuple = (128, 64),\n",
        "                 output_size: int = 10):\n",
        "        super(MLP, self).__init__() \n",
        "        self.sizes = (input_size, ) + hidden_size + (output_size, )\n",
        "        self.layers = nn.ModuleList()\n",
        "        for k in range(1, len(self.sizes)):\n",
        "          self.layers.append(nn.Linear(self.sizes[k-1], self.sizes[k]))\n",
        "          self.layers.append(nn.ReLU())\n",
        "\n",
        "    def forward(self, x): \n",
        "        x = x.view(x.size(0), -1)\n",
        "        for layer in self.layers:\n",
        "          x = layer(x)\n",
        "          # print(x.size())\n",
        "        return x"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z97kCInBXGDi"
      },
      "source": [
        "model = MLP()\n",
        "inp = torch.randn(64, 784) # (batch_size, 784)\n",
        "y = model(inp)\n"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xMe9hUWZyUN",
        "outputId": "1c0e7ff5-ef84-48ff-96fa-5e6772a024d1"
      },
      "source": [
        "model.layers"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModuleList(\n",
              "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (3): ReLU()\n",
              "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
              "  (5): ReLU()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jX8yoiNK9ZG"
      },
      "source": [
        "# pipeline\n",
        "for epoch in range(epochs):\n",
        "    \n",
        "    model.train() # formalism, useful when we have dropout\n",
        "    \n",
        "    loss_vals = []\n",
        "    \n",
        "    with tqdm(total=len(train_loader)) as pbar: # progress bar\n",
        "      for data, targets in train_loader:\n",
        "          \n",
        "        # forward pass\n",
        "        outputs = model(data)\n",
        "        \n",
        "        # loss function\n",
        "        loss = loss_func(outputs, targets)\n",
        "        \n",
        "        # record loss function values .item()\n",
        "        loss_vals.append(loss.item())\n",
        "        \n",
        "        # clean the gradient from last iteration\n",
        "        # param.grad is not zero in last iteration\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # backprop\n",
        "        # autograd\n",
        "        loss.backward()\n",
        "        \n",
        "        # stochastic gradient descent\n",
        "        # no with torch.no_grad(): block, param operation is using .data\n",
        "        optimizer.step()\n",
        "        \n",
        "        # check accuracy\n",
        "\n",
        "        # tqdm template\n",
        "        desc = f\"epoch: [{epoch+1}/{epochs}] loss: {np.mean(loss_vals):.4f}\"\n",
        "        pbar.set_description(desc)\n",
        "        pbar.update()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQlQFtslL9Gm"
      },
      "source": [
        "# How to validate?\n",
        "\n",
        "In order to make an informed choice, we need a way to *validate* that our model and our hyperparameters are a good fit to the data.\n",
        "While this may sound simple, there are some pitfalls that you must avoid to do this effectively.\n",
        "\n",
        "\n",
        "Model validation is very simple: making use of \"holdout\" validation sets and cross-validation for more robust model evaluation. We hold back some subset of the data from the training of the model, and then use this holdout set to check the model performance. \n",
        "This splitting can be done using the ``train_test_split`` utility in Scikit-Learn:\n",
        "\n",
        "## Reference:\n",
        "- Python data science handbook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGFev_UNL84b"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMVlM4y4M-x8",
        "outputId": "1bf721df-baf6-4e10-f827-0cc81bbecbd6"
      },
      "source": [
        "X = train.data.float()[:10000]\n",
        "y = train.targets[:10000]\n",
        "print(X.size(), y.size())"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10000, 28, 28]) torch.Size([10000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pkyI24fNCnU"
      },
      "source": [
        "X_tr, X_val, y_tr, y_val = \\\n",
        "train_test_split(X, y, random_state=0, train_size=0.8)\n",
        "# random_state = seed"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qi7KfZ3-YHUm",
        "outputId": "c6a5cf27-f502-4a3c-8a63-fa5b9ab0a644"
      },
      "source": [
        "print(X_tr.size(), X_val.size())"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8000, 28, 28]) torch.Size([2000, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HxCd_QpNWj5"
      },
      "source": [
        "train_set = TensorDataset(X_tr, y_tr)\n",
        "train_loader = DataLoader(train_set, batch_size=32)\n",
        "\n",
        "valid_set = TensorDataset(X_val, y_val)\n",
        "val_loader = DataLoader(valid_set, batch_size=32)"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6mkU5dlNjum"
      },
      "source": [
        "sample = next(iter(train_loader))"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-cdHDrPYXng",
        "outputId": "325c2868-cc35-4a45-a596-192bf10afcf1"
      },
      "source": [
        "sample[0].size(), sample[1].size()"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 28, 28]), torch.Size([32]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPj-DMzSaSDl",
        "outputId": "80d6dd0b-14d4-4ea9-c6c4-df4352be18b9"
      },
      "source": [
        "sample[0].dtype"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379,
          "referenced_widgets": [
            "ffb571b5191d444ea9b93e1fd6b490b8",
            "525a94290a9d4d41948436102b09971d",
            "5793aba684c8441ea3d8dd0cce68fbd7",
            "99e9c0dfa61a496dbb9bfa419377fc71",
            "ab9a55949426491cb3c411b27d356e73",
            "50625b8a8ce149af9ba3a3b9533d219b",
            "beafa0fdd6264ae485dfd8c4362fa995",
            "647056a0b1c14d029952c14a8f5cd1c2"
          ]
        },
        "id": "YojEUAzcYZEP",
        "outputId": "5edfd37f-5cd1-493c-8773-41f49a423491"
      },
      "source": [
        "# pipeline\n",
        "for epoch in range(epochs):\n",
        "    \n",
        "    model.train() # formalism, useful when we have dropout\n",
        "    \n",
        "    loss_vals = []\n",
        "    acc_on_valid = []\n",
        "    \n",
        "    with tqdm(total=len(train_loader)) as pbar: # progress bar\n",
        "      for data, targets in train_loader:\n",
        "        \n",
        "        # forward pass\n",
        "        outputs = model(data)\n",
        "        \n",
        "        # loss function\n",
        "        loss = loss_func(outputs, targets)\n",
        "        \n",
        "        # record loss function values .item()\n",
        "        loss_vals.append(loss.item())\n",
        "        \n",
        "        # clean the gradient from last iteration\n",
        "        # param.grad is not zero in last iteration\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # backprop\n",
        "        # autograd\n",
        "        loss.backward()\n",
        "        \n",
        "        # stochastic gradient descent\n",
        "        # no with torch.no_grad(): block, param operation is using .data\n",
        "        optimizer.step()\n",
        "        \n",
        "        # check accuracy (add validation here)\n",
        "        with torch.no_grad():\n",
        "           for x, y in val_loader:\n",
        "             yhat = model(x)\n",
        "             yhat = yhat.argmax(dim=-1)\n",
        "             acc = (yhat == y).float().mean()\n",
        "             acc_on_valid.append(acc)\n",
        "\n",
        "        # tqdm template\n",
        "        desc = f\"epoch: [{epoch+1}/{epochs}] loss: {np.mean(loss_vals):.2f}\"\n",
        "        desc += f\"accuracy on validation: {np.mean(acc_on_valid):.2f}\"\n",
        "        pbar.set_description(desc)\n",
        "        pbar.update()"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ffb571b5191d444ea9b93e1fd6b490b8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=250.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-156-59e36206dbc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mdesc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"accuracy on validation: {np.mean(acc_on_valid):.4f}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0;31m# maybe eager thread cleanup upon external error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m         \u001b[0;31m# If it was not run in a notebook, sp is not assigned, check for it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1243\u001b[0m         \u001b[0;31m# decrement instance pos and remove from internal set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1245\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decr_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m         \u001b[0;31m# GUI mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m_decr_instances\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_instances\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m                     \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m                     \u001b[0;32mdel\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: nocover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/_monitor.py\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwas_killed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcurrent_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUjFHly0aN_3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}