{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Math 450 Notebook 3 (Matrix Vector multiplication).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM+tQfrQUcXdenjJyMNeQls",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scaomath/wustl-math450/blob/main/Math_450_Notebook_3_(Matrix_Vector_multiplication).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LzKCusA5bZE"
      },
      "source": [
        "# Coding Lecture 3 of Math 450\n",
        "\n",
        "Overall goal of the our class: make us learn machine learning in torch package.\n",
        "- Build our own neural net using Torch's LEGO-like blocks.\n",
        "- Write torch-like code from scratch.\n",
        "- Write our own optimizer.\n",
        "\n",
        "Today's goal:\n",
        "- Use matrix vector multiplication in `torch` to build a network.\n",
        "- `Dense` layer in `nn` module.\n",
        "\n",
        "This is a worksheet version of the notebook. We can follow along during the coding lecture and then download the annotated version in our Github repository.\n",
        "\n",
        "Download this notebook at: https://github.com/scaomath/wustl-math450/blob/main/Lectures/Math_450_Notebook_3_(Matrix_Vector_multiplication).ipynb\n",
        "\n",
        "Reference: Numpy's neural network implementation from scratch: https://www.kaggle.com/scaomath/simple-mnist-numpy-from-scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soVvKDHb51Fk"
      },
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fnc7a5-o7oM9"
      },
      "source": [
        "# Gradient of a single sample\n",
        "\n",
        "We have the following neural network.\n",
        "\n",
        "<img src=\"https://sites.wustl.edu/scao/files/2021/02/3Lnn.png\" alt=\"drawing\" width=\"500\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gw2771-D5jl"
      },
      "source": [
        "## Reproducibility\n",
        "Fixing the random number generation seed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy3ITSYm9iJF"
      },
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox2iJGEbEBnh",
        "outputId": "95173ef1-e939-4a61-9ca4-8d5d254cc61e"
      },
      "source": [
        "torch.manual_seed(2) \n",
        "# in cell mode (not a single .py file), we have to put \n",
        "# torch.manual_seed(SEED) in each cell we want reproducibility\n",
        "torch.randn((5,))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.3923, -0.2236, -0.3195, -1.2050,  1.0445])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usumPTS06NWl"
      },
      "source": [
        "dtype = torch.float # single-precision float number\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "# first go to Runtime->Runtime type->Select GPU as accelerator \n",
        "# then uncomment this to run on GPU\n",
        "# device = torch.device(\"cuda:0\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6wKnuuJ9UM1"
      },
      "source": [
        "# N is the sample size (or current mini-batch size); \n",
        "# D_in is input dimension;\n",
        "# N_H is hidden dimension; \n",
        "# D_out is output dimension.\n",
        "N, D_in, N_H, D_out = 1, 10, 5, 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tgebif2c9Vbk",
        "outputId": "db87e8ac-53bd-49a5-98a9-342385f745ae"
      },
      "source": [
        "# Create random Tensors to hold input and outputs.\n",
        "# Setting requires_grad=False indicates that we do not need to compute gradients\n",
        "# with respect to these Tensors during the backward pass.\n",
        "# x: sample, is a row vector, each row represents a sample\n",
        "torch.manual_seed(42)\n",
        "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
        "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
        "print(x, '\\n' , y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.3367,  0.1288,  0.2345,  0.2303, -1.1229, -0.1863,  2.2082, -0.6380,\n",
            "          0.4617,  0.2674]]) \n",
            " tensor([[0.5349, 0.8094, 1.1103]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ1fGaDkGgyd",
        "outputId": "7157e2ef-1b29-47de-aa8b-93322f5b472a"
      },
      "source": [
        "print(x.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9Sz54FPFoy7",
        "outputId": "d286c154-ac88-4fd8-812d-3a8f40ca6283"
      },
      "source": [
        "# why using row as sample?\n",
        "X = torch.randn((5, 7)) # 5 samples, 7 features (input_dim)\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.1109,  0.0915, -2.3169, -0.2168, -1.3847, -0.8712, -0.2234],\n",
            "        [ 1.7174, -0.5920, -0.0631, -0.8286,  0.3309, -1.5576,  0.9956],\n",
            "        [-0.8798, -0.6011,  1.3123,  0.6872, -1.0892, -0.4459,  1.4451],\n",
            "        [ 0.8564,  2.2181,  0.5232,  0.3466, -0.1973, -1.0546, -0.7718],\n",
            "        [-0.1722,  0.5238,  0.0566,  0.4263,  0.5750, -0.6417, -2.2064]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCgu_de2F5Uw",
        "outputId": "1e7417d2-f005-4485-aafa-ba2568d3733c"
      },
      "source": [
        "# row corresponds to axis 0\n",
        "print(X[0]) # returns row 0 (the 1st row), single index, handy\n",
        "print(X[:, 0]) # column 0 (not convenient to track column vectors)\n",
        "print(X[..., 0]) # columns 0 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-1.1109,  0.0915, -2.3169, -0.2168, -1.3847, -0.8712, -0.2234])\n",
            "tensor([-1.1109,  1.7174, -0.8798,  0.8564, -0.1722])\n",
            "tensor([-1.1109,  1.7174, -0.8798,  0.8564, -0.1722])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uysr0EEs9Wrv"
      },
      "source": [
        "# Create random Tensors for weights.\n",
        "# Setting requires_grad=True indicates that we want to compute gradients with\n",
        "# respect to these Tensors during the backward pass.\n",
        "# because our data/target has zero mean, there is no need to include bias\n",
        "torch.manual_seed(42)\n",
        "w1 = torch.randn(D_in, N_H, \n",
        "                 device=device, \n",
        "                 dtype=dtype, \n",
        "                 requires_grad=True)\n",
        "\n",
        "w2 = torch.randn(N_H, D_out, \n",
        "                 device=device, \n",
        "                 dtype=dtype, \n",
        "                 requires_grad=True)\n",
        "# here the w1 and w2 are actually transposes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evBlkhMCHYlM",
        "outputId": "f6ea9c84-f2ca-4e21-c836-e83215b82c3d"
      },
      "source": [
        "print(w2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.5687,  1.2580, -1.5890],\n",
            "        [-1.1208,  0.8423,  0.1744],\n",
            "        [-2.1256,  0.9629,  0.7596],\n",
            "        [ 0.7343, -0.6708,  2.7421],\n",
            "        [ 0.5568, -0.8123,  1.1964]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-ZnXIjJ-b0b"
      },
      "source": [
        "## Forward pass\n",
        "\n",
        "$$\\begin{aligned}\n",
        "\\mathbf{z}^{(2)} &= W^{(1)} \\mathbf{x} + \\mathbf{b}^{(1)} \\\\\n",
        "\\mathbf{a}^{(2)} &= f(\\mathbf{z}^{(2)}) \\\\\n",
        "\\mathbf{z}^{(3)} &= W^{(2)} \\mathbf{a}^{(2)} + \\mathbf{b}^{(2)} \\\\\n",
        "h(\\mathbf{x}; W, b) &= \\mathbf{a}^{(3)} = \\mathbf{z}^{(3)}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "$\\mathbf{b}^{(1)}$ and $\\mathbf{b}^{(2)}$ are zero vector in our example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9d3rwy3-Y9v",
        "outputId": "3f89e954-cf5f-4bc1-b0b3-a3be4603d527"
      },
      "source": [
        "# code here\n",
        "z2 = x.mm(w1) # z2 is a row vector (1, 5) = (1, 10)*(10, 5)\n",
        "print(z2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.3988,  0.6874, -4.7359, -4.3096, -0.2963]], grad_fn=<MmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jj5JBEL-IAmc",
        "outputId": "298dd5e6-35c6-4fb1-d0f9-c5ae477cd2bd"
      },
      "source": [
        "# relu activation\n",
        "a2 = z2.clamp(min=0)\n",
        "print(a2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.3988, 0.6874, 0.0000, 0.0000, 0.0000]], grad_fn=<ClampBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Whzra70OISPp",
        "outputId": "2e5f6c0b-792a-47ba-bb8e-cc7e6b297790"
      },
      "source": [
        "out = a2.mm(w2)\n",
        "print(out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.9972,  1.0807, -0.5137]], grad_fn=<MmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI3Ui9NX-vfu"
      },
      "source": [
        "## Actual data in batch\n",
        "\n",
        "In the actual implementation, the data normaly comes in batch, i.e., a matrix. For example, input is a matrix $X \\in \\mathbb{R}^{N \\times d}$, $N$ is a number of samples in a batch, each row represents a sample $\\mathbf{x} \\in \\mathbb{R}^{1\\times d}$. The weight matrix $W$ is actually formulated as:\n",
        "$$\n",
        "W = \\left(\n",
        "\\begin{array}{cccc}| & | & | & | \\\\\n",
        "\\mathbf{w}_1 & \\mathbf{w}_2 & \\cdots & \\mathbf{w}_m \\\\\n",
        "| & | & | & |\n",
        "\\end{array}\\right),\n",
        "$$\n",
        "if the output dimension of the layer of interest is $m$. The vectorized formulation is, for example, from the input (layer 0, dimension $d$) to layer 1 (dimension $m$)\n",
        "$$\n",
        "A^{(1)} = X (W^{(0)})^{\\top} + B\n",
        "$$\n",
        "where $X \\in \\mathbb{R}^{N \\times d}$, $W^{(0)} \\in \\mathbb{R}^{m\\times d}$ (input from $d$ perceptrons, output from $m$ perceptrons), $B$ is a matrix with each row being the same $\\mathbf{b} \\in \\mathbb{R}^{1\\times m}$ (layer 1 has $m$ perceptrons and has $m$ biases if applicable).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjznPWjfJIIJ",
        "outputId": "dbc844f1-da1f-4127-acc9-e48f5b8ba2ed"
      },
      "source": [
        "N = 8 # 8 samples in a batch\n",
        "torch.manual_seed(42)\n",
        "X = torch.randn(N, D_in, dtype=torch.float, device=device)\n",
        "Y = torch.randn(N, D_out, dtype=torch.float, device=device)\n",
        "print(X, '\\n\\n', Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.9269,  1.4873,  0.9007, -2.1055,  0.6784, -1.2345, -0.0431, -1.6047,\n",
            "         -0.7521,  1.6487],\n",
            "        [-0.3925, -1.4036, -0.7279, -0.5594, -0.7688,  0.7624,  1.6423, -0.1596,\n",
            "         -0.4974,  0.4396],\n",
            "        [-0.7581,  1.0783,  0.8008,  1.6806,  1.2791,  1.2964,  0.6105,  1.3347,\n",
            "         -0.2316,  0.0418],\n",
            "        [-0.2516,  0.8599, -1.3847, -0.8712, -0.2234,  1.7174,  0.3189, -0.4245,\n",
            "          0.3057, -0.7746],\n",
            "        [-1.5576,  0.9956, -0.8798, -0.6011, -1.2742,  2.1228, -1.2347, -0.4879,\n",
            "         -0.9138, -0.6581],\n",
            "        [ 0.0780,  0.5258, -0.4880,  1.1914, -0.8140, -0.7360, -1.4032,  0.0360,\n",
            "         -0.0635,  0.6756],\n",
            "        [-0.0978,  1.8446, -1.1845,  1.3835,  1.4451,  0.8564,  2.2181,  0.5232,\n",
            "          0.3466, -0.1973],\n",
            "        [-1.0546,  1.2780, -0.1722,  0.5238,  0.0566,  0.4263,  0.5750, -0.6417,\n",
            "         -2.2064, -0.7508]]) \n",
            "\n",
            " tensor([[ 0.0109, -0.3387, -1.3407],\n",
            "        [-0.5854,  0.5362,  0.5246],\n",
            "        [ 1.1412,  0.0516, -0.6788],\n",
            "        [ 0.5743,  0.1877, -0.3576],\n",
            "        [-0.3165,  0.5886, -0.8905],\n",
            "        [ 0.4098, -0.9864,  0.1233],\n",
            "        [ 0.3499,  0.6173, -0.1693],\n",
            "        [ 0.2332,  4.0356,  1.2795]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlFtGEQkJv-M",
        "outputId": "750fca30-1312-4a68-a7b0-1efd246a8cc0"
      },
      "source": [
        "# Z2 is W1 multiplied with every x in this 8 sample batch\n",
        "Z2 = X.mm(w1)\n",
        "print(Z2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.6411, -2.4556, -1.5984, -4.3532,  5.3757],\n",
            "        [ 3.1372,  0.6441,  1.0954, -1.0668, -2.6129],\n",
            "        [-0.2949,  2.6706,  0.3077, -0.4743,  2.1944],\n",
            "        [-1.2595,  2.0259, -0.3845,  1.5235,  1.4738],\n",
            "        [-1.0205, -1.3909, -0.1755,  2.3356, -0.6578],\n",
            "        [ 1.9354, -0.5580,  0.6821, -1.7389,  1.0952],\n",
            "        [-1.8684,  7.3570, -2.8494, -0.8635,  5.9925],\n",
            "        [-2.6531,  3.5318, -4.8040,  0.5250,  2.0460]], grad_fn=<MmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EkxlMWHKKqt",
        "outputId": "7877d798-b108-480b-abce-71cef681b27b"
      },
      "source": [
        "A2 = Z2.clamp(min=0)\n",
        "print(A2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.6411, 0.0000, 0.0000, 0.0000, 5.3757],\n",
            "        [3.1372, 0.6441, 1.0954, 0.0000, 0.0000],\n",
            "        [0.0000, 2.6706, 0.3077, 0.0000, 2.1944],\n",
            "        [0.0000, 2.0259, 0.0000, 1.5235, 1.4738],\n",
            "        [0.0000, 0.0000, 0.0000, 2.3356, 0.0000],\n",
            "        [1.9354, 0.0000, 0.6821, 0.0000, 1.0952],\n",
            "        [0.0000, 7.3570, 0.0000, 0.0000, 5.9925],\n",
            "        [0.0000, 3.5318, 0.0000, 0.5250, 2.0460]], grad_fn=<ClampBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fj3H_SfdKX0V",
        "outputId": "90205018-ef92-40d3-d88f-8c04786a742b"
      },
      "source": [
        "# output z3\n",
        "Z3 = A2.mm(w2)\n",
        "print(Z3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 2.6286, -3.5604,  5.4129],\n",
            "        [-4.8344,  5.5440, -4.0405],\n",
            "        [-2.4255,  0.7632,  3.3249],\n",
            "        [-0.3313, -0.5127,  6.2941],\n",
            "        [ 1.7151, -1.5667,  6.4045],\n",
            "        [-1.9406,  2.2018, -1.2468],\n",
            "        [-4.9091,  1.3290,  8.4527],\n",
            "        [-2.4337,  0.9607,  4.5034]], grad_fn=<MmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TktdIThoJG6s"
      },
      "source": [
        "## Torch's nn module\n",
        "\n",
        "We will demo this batch-based operation using `torch`'s neural network module `nn`. `nn.Linear` applies an (affine) linear transformation to the incoming data:\n",
        "$$\n",
        "Y = X W^{\\top} + \\mathbf{b}\n",
        "$$\n",
        "\n",
        "Reference: https://pytorch.org/docs/stable/nn.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DIgmIGc_Rno"
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71raJ2Fu_PGF"
      },
      "source": [
        "layer1 = nn.Linear(10, 5) \n",
        "# Wx+b transforms (10,1) vector to (5,1) vector\n",
        "# or xW^T transforms (1,10) vector to (1,5) vector \n",
        "layer2 = nn.Linear(5,3)\n",
        "activation = nn.ReLU()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np4MVu5J_QCi",
        "outputId": "dc872766-7ef7-4b30-8c5c-64967aa56fc5"
      },
      "source": [
        "Z2 = layer1(X)\n",
        "print(Z2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.2808,  0.3782, -0.4373,  0.2746,  0.4777],\n",
            "        [-0.1306, -0.6695,  0.5177, -0.0283, -0.7960],\n",
            "        [-1.6454, -0.8339, -0.0197, -0.4252, -0.4004],\n",
            "        [-0.1117,  0.1235,  0.1512, -0.2560, -0.1221],\n",
            "        [-0.1911,  0.0570, -0.5551, -1.2714, -0.6000],\n",
            "        [-0.0703,  0.9140, -0.7532, -0.8300, -0.4561],\n",
            "        [-1.3858, -0.1712, -0.2908,  0.0939, -0.4832],\n",
            "        [-0.9507, -0.1689, -0.9392, -0.6117, -0.8422]],\n",
            "       grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvNxvLBeLcjf",
        "outputId": "50d5d312-b2ee-406c-910d-59d6144acc75"
      },
      "source": [
        "A2 = activation(Z2)\n",
        "print(A2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.2808, 0.3782, 0.0000, 0.2746, 0.4777],\n",
            "        [0.0000, 0.0000, 0.5177, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.1235, 0.1512, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0570, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.9140, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0939, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2kee1pfLo6p"
      },
      "source": [
        "def forward(x):\n",
        "  '''\n",
        "  forward pass function\n",
        "  '''\n",
        "  layer1 = nn.Linear(10,5)\n",
        "  layer2 = nn.Linear(5,3)\n",
        "  act = nn.ReLU()\n",
        "  x = layer1(x) # z2\n",
        "  x = act(x) # a2\n",
        "  x = layer2(x) # z3\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtiOHMaaMG9g",
        "outputId": "05a25ad2-13c1-4281-c500-eddbf53fad80"
      },
      "source": [
        "output = forward(X)\n",
        "print(output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.5598e-01, -5.9261e-01, -5.2584e-01],\n",
            "        [-7.8872e-02,  6.1956e-04, -2.0961e-01],\n",
            "        [-2.0640e-01,  3.4190e-01, -3.4736e-01],\n",
            "        [-8.7701e-03,  9.9241e-02, -3.1565e-01],\n",
            "        [ 1.9981e-01, -4.6423e-01, -6.2108e-01],\n",
            "        [-8.0052e-02,  6.6529e-02, -2.3789e-01],\n",
            "        [-1.8169e-01,  1.0619e-01, -2.3450e-01],\n",
            "        [ 1.4324e-01, -3.5152e-01, -4.9707e-01]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkFMOc5FAMiW"
      },
      "source": [
        "## Gradient in Torch: autograd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFwWAu0kAL_3"
      },
      "source": [
        "a = torch.tensor([2., 3.], requires_grad=True)\n",
        "b = torch.tensor([6., 4.], requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7dd9vTSNUdd",
        "outputId": "9e448de4-29cf-4497-d37f-8c3de18103d3"
      },
      "source": [
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2., 3.], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieBVxA66Aehx"
      },
      "source": [
        "Q = 3*a**3 - b**2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyE_aIRbMfFP",
        "outputId": "311fe0d5-49e6-423d-ab0c-18651c4d8ead"
      },
      "source": [
        "print(Q)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-12.,  65.], grad_fn=<SubBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzfJ0ypFApvm",
        "outputId": "aaf0f509-ba31-4878-e5b5-347923ba426e"
      },
      "source": [
        "L = Q.sum()\n",
        "print(L)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(53., grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oucQIwEXAqRA"
      },
      "source": [
        "L.backward() # backprop in a simple command"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5IleofsNG6w"
      },
      "source": [
        "$\\frac{\\partial L}{\\partial \\mathbf{a}}$ should be the same shape with $\\mathbf{a}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLFIjKn4BCPj",
        "outputId": "dc818652-61b3-432e-d4c6-35e6c75c18e6"
      },
      "source": [
        "a.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([36., 81.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0olov7nNgPc",
        "outputId": "df613003-b8d3-474d-d562-80f86a776ba2"
      },
      "source": [
        "(9*a**2).detach() # detach means we do not track the gradient"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([36., 81.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RCbt3bENs8K",
        "outputId": "9ca1d501-e849-4732-839b-9b48a2d18242"
      },
      "source": [
        "b.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-12.,  -8.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bw3ADv1QNtkI",
        "outputId": "cf4c8b53-f4ca-41ce-8e49-a7f528b4c7b6"
      },
      "source": [
        "(-2*b).detach()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-12.,  -8.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nTs27dyNxep"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}