{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1: Transition from NumPy to PyTorch\n",
    "\n",
    "Name: Chenthuran Abeyakaran\n",
    "\n",
    "Wustlkey: cjabeyakaran\n",
    "\n",
    "Partner Name (if applicable):\n",
    "\n",
    "Partner Wustlkey (if applicable):\n",
    "\n",
    "### Submission instructions\n",
    "\n",
    "- Submit the modified python notebook as homework submission.\n",
    "- Group submission is enabled, you can submit this coding assignment with up to 1 teammate in our class. For instruction of how to do a group submission. Please refer to Canvas useful links.\n",
    "- Do not change the number of cells! Please work in the cell provided. If we need extra cells for debugging and testing purposes, we can work at the end of this notebook, save everything as a backup for review, and delete the extra cells in the submitted version.\n",
    "\n",
    " \n",
    "\n",
    "### Instructions\n",
    "Do **not** use for loops in any of our solutions! Efficieny will be graded as well. For example if a problem asks us generate an array from 0 to 9: then\n",
    "```python\n",
    "x = []\n",
    "for i in range(10):\n",
    "    x.append(i)\n",
    "```\n",
    "this will only result a partial credit while\n",
    "```python\n",
    "x = np.arange(10)\n",
    "```\n",
    "or\n",
    "```python\n",
    "x = torch.arange(10)\n",
    "```\n",
    "will yield a full score.\n",
    "\n",
    "### Problems\n",
    "Below are 6 problems that explore different common used tools in Numpy and how to translate them into Torch codes. Each problem gives examples demonstrating the concept and has an associated coding task. Complete the coding tasks for credit.\n",
    "\n",
    "### Grading\n",
    "This homework has 6 problems, 4 points each for problem 1-5 and 10 points for the last problem. The homework will be graded and the grade counts towards your course grade. The homework will weigh 50% compared to the subsequent assignemnts (it's not fully weighted...). \n",
    "\n",
    "## Coding environments and submission\n",
    "If we do not have `torch` installed on your computer, we have three ways to upload this notebook to [Google colab](https://colab.research.google.com/)ï¼š\n",
    "\n",
    "1. Open up Google Colab, choose `Upload` to upload this template and work there. After we have done working we can select `File->Download .ipynb`.\n",
    "2. Open up Google Colab, choose either `GitHub` or `Google Drive` to select the uploaded notebook in the corresponding website. After done working, we can sync the file to the corresponding GitHub or Google Drive copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Me First\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D Basic Array Functions\n",
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = torch.tensor([\n",
    "    55.70000076,  51.40000153,  50.5       ,  75.69999695,\n",
    "    58.40000153,  40.09999847,  61.5       ,  57.09999847,\n",
    "    60.90000153,  66.59999847,  60.40000153,  68.09999847,\n",
    "    66.90000153,  53.40000153,  48.59999847,  56.79999924,\n",
    "    71.59999847,  58.40000153,  70.40000153,  41.20000076\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(55.7000)\n",
      "tensor(75.7000)\n"
     ]
    }
   ],
   "source": [
    "# Accessing elements\n",
    "print(arr1[0])\n",
    "print(arr1[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([55.7000, 51.4000, 50.5000])\n",
      "tensor([55.7000, 51.4000, 50.5000])\n",
      "tensor([58.4000, 70.4000, 41.2000])\n",
      "tensor([55.7000, 51.4000, 50.5000, 75.7000, 58.4000, 40.1000, 61.5000, 57.1000,\n",
      "        60.9000, 66.6000, 60.4000, 68.1000, 66.9000, 53.4000, 48.6000, 56.8000,\n",
      "        71.6000, 58.4000, 70.4000, 41.2000])\n"
     ]
    }
   ],
   "source": [
    "#Slicing\n",
    "print(arr1[0:3])\n",
    "print(arr1[:3])\n",
    "print(arr1[17:])\n",
    "print(arr1[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.float64\n",
      "torch.bool\n"
     ]
    }
   ],
   "source": [
    "#Element Types\n",
    "print(arr1.dtype)\n",
    "print(torch.tensor([0, 1, 2, 3]).dtype)\n",
    "print(torch.tensor([1.0, 1.5, 2.0, 2.5]).dtype)\n",
    "print(torch.tensor([1.0, 1.5, 2.0, 2.5], dtype=torch.float64).dtype)\n",
    "print(torch.tensor([True, False, True]).dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array 0-th entry has value 55.70000076293945\n",
      "Array 1-th entry has value 51.400001525878906\n",
      "Array 2-th entry has value 50.5\n",
      "Array 3-th entry has value 75.69999694824219\n",
      "Array 4-th entry has value 58.400001525878906\n",
      "Array 5-th entry has value 40.099998474121094\n",
      "Array 6-th entry has value 61.5\n",
      "Array 7-th entry has value 57.099998474121094\n",
      "Array 8-th entry has value 60.900001525878906\n",
      "Array 9-th entry has value 66.5999984741211\n",
      "Array 10-th entry has value 60.400001525878906\n",
      "Array 11-th entry has value 68.0999984741211\n",
      "Array 12-th entry has value 66.9000015258789\n",
      "Array 13-th entry has value 53.400001525878906\n",
      "Array 14-th entry has value 48.599998474121094\n",
      "Array 15-th entry has value 56.79999923706055\n",
      "Array 16-th entry has value 71.5999984741211\n",
      "Array 17-th entry has value 58.400001525878906\n",
      "Array 18-th entry has value 70.4000015258789\n",
      "Array 19-th entry has value 41.20000076293945\n"
     ]
    }
   ],
   "source": [
    "# Looping - AVOID THIS!\n",
    "\n",
    "for i in range(len(arr1)):\n",
    "    element = arr1[i]\n",
    "    print(f'Array {i}-th entry has value {element}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(58.6850)\n",
      "tensor(9.5809)\n",
      "tensor(75.7000)\n",
      "tensor(1173.7000)\n"
     ]
    }
   ],
   "source": [
    "# (Almost) Every numpy functions has it torch counterparts\n",
    "print(arr1.mean())\n",
    "print(arr1.std())\n",
    "print(arr1.max())\n",
    "print(arr1.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "Fill in the following cell to calculate the maximum of the first half (first `len(arr1)//2` elements) and the second half of the array using slicing and the built-in `max()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max of the 1st half: 75.69999694824219; Max of the 2nd half: 71.5999984741211\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "max_1st_half = arr1[: len(arr1)//2].max()\n",
    "max_2nd_half = arr1[len(arr1)//2: ].max()\n",
    "\n",
    "print(f\"Max of the 1st half: {max_1st_half}; Max of the 2nd half: {max_2nd_half}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D Arithmetic and Logic\n",
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 4, 4, 6])\n",
      "tensor([0, 0, 2, 2])\n",
      "tensor([1, 4, 3, 8])\n",
      "tensor([1, 1, 3, 2])\n",
      "tensor([ 1,  4,  3, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/pip-req-build-w9kte7xz/aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n"
     ]
    }
   ],
   "source": [
    "# Arithmetic operations between 2 torch tensors\n",
    "a = torch.tensor([1, 2, 3, 4])\n",
    "b = torch.tensor([1, 2, 1, 2])\n",
    "\n",
    "print(a + b)\n",
    "print(a - b)\n",
    "print(a * b)\n",
    "print(a / b)\n",
    "print(a ** b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 4, 5, 6])\n",
      "tensor([-1,  0,  1,  2])\n",
      "tensor([2, 4, 6, 8])\n",
      "tensor([0, 1, 1, 2])\n",
      "tensor([ 1,  4,  9, 16])\n"
     ]
    }
   ],
   "source": [
    "# Arithmetic operations between a torch tensor and a single number  \n",
    "a = torch.tensor([1, 2, 3, 4])\n",
    "b = 2\n",
    "\n",
    "print(a + b)\n",
    "print(a - b)\n",
    "print(a * b)\n",
    "print(a / b)\n",
    "print(a ** b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ True, False, False, False])\n",
      "tensor([ True,  True,  True, False])\n",
      "tensor([False, False,  True,  True])\n",
      "tensor([ True,  True, False, False])\n",
      "tensor([False, False, False, False])\n",
      "tensor([True, True, True, True])\n",
      "tensor([ True,  True, False, False])\n"
     ]
    }
   ],
   "source": [
    "# Logical operations with torch tensors\n",
    "a = torch.tensor([True, True, False, False])\n",
    "b = torch.tensor([True, False, True, False])\n",
    "\n",
    "print(a & b)\n",
    "print(a | b)\n",
    "print(~a)\n",
    "\n",
    "print(a & True)\n",
    "print(a & False)\n",
    "\n",
    "print(a | True)\n",
    "print(a | False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False,  True,  True])\n",
      "tensor([False,  True,  True,  True])\n",
      "tensor([ True, False, False, False])\n",
      "tensor([ True,  True, False, False])\n",
      "tensor([False,  True, False, False])\n",
      "tensor([ True, False,  True,  True])\n"
     ]
    }
   ],
   "source": [
    "# Comparison operations of torch tensors to a number\n",
    "a = torch.tensor([1, 2, 3, 4])\n",
    "b = 2\n",
    "    \n",
    "print(a > b)\n",
    "print(a >= b)\n",
    "print(a < b)\n",
    "print(a <= b)\n",
    "print(a == b)\n",
    "print(a != b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "Fill in this section to compute a `torch.tensor` containing the average of the two given arrays to achieve the effect of the following `for` loop:\n",
    "```python\n",
    "avg = []\n",
    "for i in range(len(arr1)):\n",
    "    avg.append((arr1[i] + arr2[i])/2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 96.4160, 102.6443, 101.4113,  93.3163, 103.4556,  98.1482, 102.3511,\n",
      "         91.7785,  92.8355,  89.6558,  99.2187,  98.4843,  94.1728, 117.3351,\n",
      "         98.2756,  33.0404,  41.9052,  90.9630,  57.0840,  93.0602])\n"
     ]
    }
   ],
   "source": [
    "arr1 = torch.tensor([\n",
    "    97.35583,  104.62379,  103.02998,   95.14321,  103.69019,\n",
    "    98.49185,  100.88828,   95.43974,   92.11484,   91.54804,\n",
    "    95.98029,   98.22902,   96.12179,  119.28105,   97.84627,\n",
    "    29.07386,   38.41644,   90.70509,   51.7478 ,   95.45072\n",
    "])\n",
    "\n",
    "arr2 = torch.tensor([\n",
    "     95.47622,  100.66476,   99.7926 ,   91.48936,  103.22096,\n",
    "     97.80458,  103.81398,   88.11736,   93.55611,   87.76347,\n",
    "    102.45714,   98.73953,   92.22388,  115.3892 ,   98.70502,\n",
    "     37.00692,   45.39401,   91.22084,   62.42028,   90.66958\n",
    "])\n",
    "\n",
    "'''\n",
    "    \n",
    "'''\n",
    "\n",
    "# your code here\n",
    "arr_avg = (arr1 + arr2)/2\n",
    "\n",
    "print(arr_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D Boolean (Fancy and Fast) Indexing\n",
    "###  Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2])\n",
      "tensor([1, 3])\n"
     ]
    }
   ],
   "source": [
    "# Using index arrays\n",
    "a = torch.tensor([1, 2, 3, 4])\n",
    "b = torch.tensor([True, True, False, False])\n",
    "    \n",
    "print(a[b])\n",
    "print(a[torch.tensor([True, False, True, False])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3, 2])\n",
      "tensor([2, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# Creating the index array using vectorized operations (Recall ReLU implemented in class)\n",
    "a = torch.tensor([1, 2, 3, 2, 1])\n",
    "b = (a >= 2)\n",
    "    \n",
    "print(a[b])\n",
    "print(a[a >= 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False,  True, False,  True, False])\n",
      "tensor([2, 4])\n"
     ]
    }
   ],
   "source": [
    "# Creating the index array using vectorized operations on another array\n",
    "a = torch.tensor([1, 2, 3, 4, 5])\n",
    "b = torch.tensor([1, 2, 3, 2, 1])\n",
    "    \n",
    "print(b == 2)\n",
    "print(a[b == 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "\n",
    "Fill in the following cell using the boolean indexing vectorization technique to calculate an array that can be achieved using the following `for` loop:\n",
    "```python\n",
    "result = []\n",
    "for i in range(len(arr1)):\n",
    "    if arr1[i] < 60:\n",
    "        result.append(arr2[i])\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  4,   5,   3,  12,   4,  35,  38,  37,   3,   3,  68,   2, 249,   2,\n",
      "        127,  35])\n"
     ]
    }
   ],
   "source": [
    "arr1 = torch.tensor([\n",
    "       12.89697233,    0.        ,   64.55043217,    0.        ,\n",
    "       24.2315615 ,   39.991625  ,    0.        ,    0.        ,\n",
    "      147.20683783,    0.        ,    0.        ,    0.        ,\n",
    "       45.18261617,  157.60454283,  133.2434615 ,   52.85000767,\n",
    "        0.        ,   54.9204785 ,   26.78142417,    0.\n",
    "])\n",
    "\n",
    "arr2 = torch.tensor([4,   5,  37,   3,  12,   \n",
    "                 4,  35,  38,   5,  37,   \n",
    "                 3,   3,  68,  38,  98,   \n",
    "                 2, 249,   2, 127,  35])\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "\n",
    "# your code here\n",
    "result = arr2[arr1 < 60]\n",
    "\n",
    "print(result)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Basic Functions: Indexing, Axis\n",
    "### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat1 = torch.tensor([\n",
    "    [   0,    0,    2,    5,    0],\n",
    "    [1478, 3877, 3674, 2328, 2539],\n",
    "    [1613, 4088, 3991, 6461, 2691],\n",
    "    [1560, 3392, 3826, 4787, 2613],\n",
    "    [1608, 4802, 3932, 4477, 2705],\n",
    "    [1576, 3933, 3909, 4979, 2685],\n",
    "    [  95,  229,  255,  496,  201],\n",
    "    [   2,    0,    1,   27,    0],\n",
    "    [1438, 3785, 3589, 4174, 2215],\n",
    "    [1342, 4043, 4009, 4665, 3033]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2328)\n",
      "tensor([[2328, 2539],\n",
      "        [6461, 2691]])\n",
      "tensor([1478, 3877, 3674, 2328, 2539])\n"
     ]
    }
   ],
   "source": [
    "# Accessing elements\n",
    "print(mat1[1, 3])\n",
    "print(mat1[1:3, 3:5])\n",
    "print(mat1[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1478, 3877, 3676, 2333, 2539])\n",
      "tensor([   0, 5355, 5701, 4952, 6410, 5509,  324,    2, 5223, 5385])\n"
     ]
    }
   ],
   "source": [
    "# Vectorized operations on rows or columns\n",
    "print(mat1[0, :] + mat1[1, :])\n",
    "print(mat1[:, 0] + mat1[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2,  3,  4],\n",
      "        [ 6,  7,  8],\n",
      "        [10, 11, 12]])\n"
     ]
    }
   ],
   "source": [
    "# Vectorized operations on entire arrays\n",
    "a = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "b = torch.tensor([[1, 1, 1], [2, 2, 2], [3, 3, 3]])\n",
    "print(a + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(45)\n",
      "tensor([12, 15, 18])\n",
      "tensor([ 6, 15, 24])\n"
     ]
    }
   ],
   "source": [
    "# torch axis argument\n",
    "a = torch.tensor([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "])\n",
    "    \n",
    "print(a.sum())\n",
    "print(a.sum(axis=0))\n",
    "print(a.sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "\n",
    "\n",
    "Fill in the following cell to achieve the effect of the `for` for the array `mat1` above, store the maximum entry of each row of a list version of `mat1`:\n",
    "\n",
    "```python\n",
    "mat1 = [[   0,    0,    2,    5,    0],\n",
    "    [1478, 3877, 3674, 2328, 2539],\n",
    "    [1613, 4088, 3991, 6461, 2691],\n",
    "    [1560, 3392, 3826, 4787, 2613],\n",
    "    [1608, 4802, 3932, 4477, 2705],\n",
    "    [1576, 3933, 3909, 4979, 2685],\n",
    "    [  95,  229,  255,  496,  201],\n",
    "    [   2,    0,    1,   27,    0],\n",
    "    [1438, 3785, 3589, 4174, 2215],\n",
    "    [1342, 4043, 4009, 4665, 3033]]\n",
    "row_max = []\n",
    "for row in mat1:\n",
    "    row_max.append(max(row))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   5, 3877, 6461, 4787, 4802, 4979,  496,   27, 4174, 4665])\n"
     ]
    }
   ],
   "source": [
    "row_max = mat1.max(axis=1).values\n",
    "print(row_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5\n",
    "\n",
    "Fill in the following cell to achieve the effect of the `for` for the array `mat1` above, store the index of the maximum entry of each row of a list version of `mat1`:\n",
    "\n",
    "```python\n",
    "mat1 = [[   0,    0,    2,    5,    0],\n",
    "    [1478, 3877, 3674, 2328, 2539],\n",
    "    [1613, 4088, 3991, 6461, 2691],\n",
    "    [1560, 3392, 3826, 4787, 2613],\n",
    "    [1608, 4802, 3932, 4477, 2705],\n",
    "    [1576, 3933, 3909, 4979, 2685],\n",
    "    [  95,  229,  255,  496,  201],\n",
    "    [   2,    0,    1,   27,    0],\n",
    "    [1438, 3785, 3589, 4174, 2215],\n",
    "    [1342, 4043, 4009, 4665, 3033]]\n",
    "index_max = []\n",
    "for row in mat1:\n",
    "    tmp = row.index(max(row))\n",
    "    index_max.append(index_max)\n",
    "```\n",
    "\n",
    "Hint: the function `argmax()` in PyTorch may be helpful: https://pytorch.org/docs/stable/generated/torch.argmax.html, which can be either applied as a function or as a method for the tensor `a.argmax()` with an `axis=` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 1, 3, 3, 1, 3, 3, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "index_max = mat1.argmax(axis=1)\n",
    "\n",
    "print(index_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtime Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to be able to generate random numbers for hte next problem. `PyTorch` also all sorts of random number generator similar to `numpy.random` submodule. \n",
    "\n",
    "We can use `?` to access the documentation of every function, so keep it in mind for easy access to documentations! If we are in Colab or Visual Studio Code, hovering the mouse over a function pops up the documentation as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "?torch.randn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Problem 6\n",
    "\n",
    "Using `torch.randn` function, which takes in inputs `(n,m)`, to generate a random 2d array of `n` rows and `m` columns. \n",
    "\n",
    "Note: we should format the code as `torch.randn((2,5))` not `torch.randn(2,5)` if we want to generate a 2 by 5 random matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_row_sums_loop(random_2d_array):\n",
    "    \"\"\"\n",
    "    Fill in this function to calculate row sums of 2d_array using a for loop.\n",
    "    \"\"\" \n",
    "    # your code here\n",
    "    result = []\n",
    "    for row in random_2d_array:\n",
    "        result.append(sum(row))\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_row_sums_vec(random_2d_array):\n",
    "    \"\"\"\n",
    "    Fill in this function to calculate row sums of 2d_array \n",
    "    using pytorch builtin vectorized functions.\n",
    "    \"\"\"\n",
    "    # your code here\n",
    "    result = random_2d_array.sum(axis=1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you done with the functions above, run this to compare runtime of for loops and numpy functions. Play with the matrix dimesions to see the effect! Hint: for the non-vectorized function it should take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop: 4.837149381637573 secs.\n",
      "vec: 0.0010809898376464844 secs.\n"
     ]
    }
   ],
   "source": [
    "# generate a random 2d array\n",
    "num_rows = 1000\n",
    "num_cols = 1000\n",
    "random_2d_array = generate_random_2d_array(num_rows, num_cols)\n",
    "\n",
    "start = time.time()\n",
    "# calculate row sums by for loop\n",
    "calculate_row_sums_loop(random_2d_array)\n",
    "end = time.time()\n",
    "print(f\"loop: {end - start} secs.\")\n",
    "\n",
    "start = time.time()\n",
    "# calculate row sums by for np.sum\n",
    "calculate_row_sums_vec(random_2d_array)\n",
    "end = time.time()\n",
    "print(f\"vec: {end - start} secs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra cell\n",
    "def generate_random_2d_array(num_rows, num_cols):\n",
    "    return torch.randn((num_rows, num_cols))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
