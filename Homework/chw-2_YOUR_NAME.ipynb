{
 "cells": [
  {
   "source": [
    "<a href=\"https://colab.research.google.com/github/scaomath/wustl-math450/blob/main/Homework/chw-2_YOUR_NAME.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2: Vectorization (`*` and `mm` in `torch` and `Linear` in `torch.nn`)\n",
    "Name:\n",
    "\n",
    "Wustlkey:\n",
    "\n",
    "Partner Name (if applicable):\n",
    "\n",
    "Partner Wustlkey (if applicable):\n",
    "\n",
    "### Submission instructions\n",
    "\n",
    "- Submit the modified python notebook as homework submission.\n",
    "- Group submission is enabled, you can submit this coding assignment with up to 1 teammate in our class. For instruction of how to do a group submission. Please refer to Canvas useful links.\n",
    "- Do not change the number of cells! Please work in the cell provided. If we need extra cells for debugging and testing purposes, we can work at the end of this notebook, save everything as a backup for review, and delete the extra cells in the submitted version.\n",
    "\n",
    " \n",
    "\n",
    "### Instructions\n",
    "Do **not** use `for` loops for computational purpose in any of our solutions! We are allowed to use `for` loops to display figures etc.\n",
    "Efficieny will be graded as well. For example if a problem asks us generate an array from 0 to 9: then\n",
    "```python\n",
    "x = []\n",
    "for i in range(10):\n",
    "    x.append(i)\n",
    "```\n",
    "this will only result a partial credit while\n",
    "```python\n",
    "x = np.arange(10)\n",
    "```\n",
    "or\n",
    "```python\n",
    "x = torch.arange(10)\n",
    "```\n",
    "will yield a full score.\n",
    "\n",
    "### Problems\n",
    "Below are 4 problems that explore elementwise operations, matrix-vector multiplication, and the simplest layer in `torch.nn` module. Each problem gives examples demonstrating the concept and has an associated coding task. Complete the coding tasks for credit.\n",
    "\n",
    "### Grading\n",
    "This homework has 4 problems, 5 points each. The homework will be graded and the grade counts towards your course grade. \n",
    "\n",
    "## Coding environments and submission\n",
    "If we do not have `torch` installed on your computer, we have three ways to upload this notebook to [Google colab](https://colab.research.google.com/)：\n",
    "\n",
    "1. Open up Google Colab, choose `Upload` to upload this template and work there. After we have done working we can select `File->Download .ipynb`.\n",
    "2. Open up Google Colab, choose either `GitHub` or `Google Drive` to select the uploaded notebook in the corresponding website. After done working, we can sync the file to the corresponding GitHub or Google Drive copy.\n",
    "3. Use the \"Open in Colab\" button at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Me First\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "source": [
    "## Dataset\n",
    "\n",
    "\n",
    "\"MNIST (\"Modified National Institute of Standards and Technology\") is the de facto “hello world” dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.\"\n",
    "\n",
    "In the following cells, we will learn how to load and view this dataset for our toy models. \n",
    "\n",
    "Read more:[https://www.kaggle.com/c/digit-recognizer](https://www.kaggle.com/c/digit-recognizer)\n",
    "\n",
    "\n",
    "<a title=\"By Josef Steppan [CC BY-SA 4.0 (https://creativecommons.org/licenses/by-sa/4.0)], from Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:MnistExamples.png\"><img width=\"512\" alt=\"MnistExamples\" src=\"https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png\"/></a>\n",
    "\n",
    "\n",
    "---- \n",
    "This code is adopted from the pytorch examples repository. \n",
    "It is licensed under BSD 3-Clause \"New\" or \"Revised\" License.\n",
    "Source: https://github.com/pytorch/examples/\n",
    "LICENSE: https://github.com/pytorch/examples/blob/master/LICENSE"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision \n",
    "from __future__ import print_function\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages that help us plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the data\n",
    "train = datasets.MNIST('../data', train=True, download=True, transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the data into a loader, every iteration 1 sample is loaded\n",
    "train_loader = DataLoader(train, batch_size=1, shuffle=True, num_workers=2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(train_loader) # set the loader to be an iterator\n",
    "images, labels = next(data_iter) # next returns the next item in an iterator"
   ]
  },
  {
   "source": [
    "`image` is now a `28x28` matrix, with entries varying between 0 and 1. Once being plotted by `imshow` function as a `28x28` image, each pixel's brightness is decided by the matrix's entry value. Here axes are used but we can always just call `plt.imshow` instead."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "image = images[0].squeeze()\n",
    "label = labels.squeeze()\n",
    "_, ax = plt.subplots(1)\n",
    "ax.imshow(image, cmap='gray'); \n",
    "ax.set_title(f'Label: {label}', color= 'black', fontsize=25);"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## Data manipulation in higher dimensions\n",
    "\n",
    "Load more images with label 8. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (train.train_labels==8)\n",
    "labels_new = train.train_labels[idx]\n",
    "data = train.train_data[idx]/255"
   ]
  },
  {
   "source": [
    "Now we randomly pick 10 of them using `numpy.random.choice` function, notice the shape of the data should be `(10, 28, 28)` whereas the dimension 0 (axis 0) represents the indices of the image."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data_all = len(data)\n",
    "idx = np.random.choice(range(n_data_all), size=10)\n",
    "data_new = data[idx]\n",
    "data_new = torch.tensor(data_new, dtype=torch.float)\n",
    "print(data_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data_new[0,:,:], cmap='gray'); # plot the first sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "For `data_new`, get a smoothened 8 image `average_8` by averaging axis 0, use a single line of code to achieve the result of the following `for` loop:\n",
    "\n",
    "```python\n",
    "n_sample = len(data_new)\n",
    "average_8 = torch.zeros_like(data_new[0], dtype=torch.float)\n",
    "for i in range(n_sample):\n",
    "    average_8 += data_new[i,:,:]/n_sample\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_8 = None      # Replace this with your code\n",
    "\n",
    "try:\n",
    "    plt.imshow(average_8, cmap='gray'); # this should look like a smoothened 8\n",
    "except TypeError:\n",
    "    print(\"Please get an averaged tensor first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `torch.nn.Linear`\n",
    "\n",
    "We know that the layer `Linear` is essentially applying a linear transform to every sample in the data. In the following example, a linear layer is initialized with no bias, transforms a flattened `28x28` matrix to a long vector of `14*14`, then reshape this vector back to `14x14` matrix.\n",
    "\n",
    "If we plot this matrix, we will find that nothing is discernible anymore. This is the nature of the neural network, transforms \"low-level\" concrete features to more abstracted features. Even after being trained, nn retains this black-box nature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = nn.Linear(28*28, 14*14, bias=False)\n",
    "x0 = data_new[0].flatten() # flatten (28, 28) matrix to a (784, ) vector\n",
    "x1 = layer1(x0) # apply the linear transform\n",
    "image = x1.view(14,14).detach().numpy() # reshape (196, ) vector to (14,14)\n",
    "plt.imshow(image, cmap='gray'); "
   ]
  },
  {
   "source": [
    "Notice that `torch` layer can handle data in batch."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(data_new)\n",
    "X0 = data_new.view(n_samples, -1) \n",
    "X1 = layer1(X0)\n",
    "X2 = X1.view(-1,14,14) # -1 detects the batch size automatically\n",
    "print(X2.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "Implement in the following cell `nn.Linear` from scratch using `torch.mm` on `data_new` of a linear layer with out bias to achieve the result of the following `for` loop. The following `for` loop can be modified to three lines of code with a reshape using `view` function, a matrix-matrix multiplication, reshape using `view` again.\n",
    "\n",
    "```python\n",
    "W0 = torch.randn(28*28, 14*14)\n",
    "n_samples = len(data_new)\n",
    "X0 = data_new\n",
    "X1 = torch.zeros(n_samples, 14*14, 1)\n",
    "for i in range(n_samples):\n",
    "    sample = X0[i,:,:].view(-1,1)\n",
    "    X1[i,:] = W0.T.mm(sample)\n",
    "X2 = X1.view(-1,14,14)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this with your code\n",
    "# your code here\n",
    "X2 = None   \n",
    "\n",
    "\n",
    "print(X2.size()) # should be (10, 14, 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling, pooling, and padding\n",
    "\n",
    "###  Examples\n",
    "In practice of computer vision, an image is sometimes downsampled to reduce the dimension and the size of the neural network. We can do so by \"pooling\": for example, for an `28x28` image, we can \"pool\" it by taking the maximum of a `2x2` block to downsample an image from `28x28` to `14x14`.\n",
    "\n",
    "An example can be viewed as follows:\n",
    "\n",
    "<img width=\"512\" alt=\"MnistExamples\" src=\"https://sites.wustl.edu/scao/files/2021/02/MaxpoolSample2.png\"/></a>\n",
    "\n",
    "\"Padding\" is the operation of adding zeros on the outer rims of a matrix to make it bigger, it is useful in neural network to keep the size consistent. For example for the folllowing `2x2` matrix:\n",
    "```\n",
    "tensor ([[1 , 2],\n",
    "         [3, 4]])\n",
    "\n",
    "```\n",
    "We can pad this matrix by zeros with a padding size 2 as follows:\n",
    "```\n",
    "tensor([[ 0,  0,  0,  0,  0,  0],\n",
    "        [ 0,  0,  0,  0,  0,  0],\n",
    "        [ 0,  0,  1,  2,  0,  0],\n",
    "        [ 0,  0,  3,  4,  0,  0],\n",
    "        [ 0,  0,  0,  0,  0,  0],\n",
    "        [ 0,  0,  0,  0,  0,  0]])\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # pool of square window of size=2, stride=2 as shown in the image above\n",
    " # size: the size of the square pooling window\n",
    " # stride: how many entries does the pooling window moves each time, if the stride is 1, then there is overlapping for a size 2 pooling window\n",
    " layer2 = nn.MaxPool2d(2, stride=2) \n",
    " X0 = data_new\n",
    " X1 = layer2(X0)\n",
    " print(X1.size())\n",
    " plt.imshow(X1[1], cmap='gray'); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "Fill in the following cell implementation a vectorized function to perform a zero-padding on the max-pooled data with size `(10,14,14)`, and transform each sample in it back to `(10,28,28)` without `for` loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "X1_upsample = None\n",
    "\n",
    "print(X1_upsample.size()) # (10, 28, 28)\n",
    "plt.imshow(X1_upsample[1], cmap='gray'); # should be an eight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `loss.backward()`\n",
    "\n",
    "The `backward()` operation on any tensor `w` initialized with `requires_grad=True` will compute the gradient of `w`, and we can retrieve its gradient by `w.grad`. For example in the following cell, the gradient of $W^{T}$ is computed for \n",
    "$$\n",
    "L = \\frac{1}{20}\\sum_{i=1}^{10} |W\\boldsymbol{x}^{(i)} -y^{(i)} |^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "n_samples = len(data_new)\n",
    "\n",
    "# X[i] is a row vector representing a sample\n",
    "X = torch.tensor(data_new.view(-1, 28*28), requires_grad=False) \n",
    "\n",
    "# y[i] is a made-up label for i-th sample\n",
    "y = torch.randn((n_samples, 1), requires_grad=False)\n",
    "\n",
    "# W is the weight matrix transposed \n",
    "W = torch.randn((28*28, 1), requires_grad=True)\n",
    "L = 0.5*(X.mm(W) - y).square().mean()\n",
    "\n",
    "# backprop\n",
    "L.backward()\n",
    "\n",
    "# gradient\n",
    "with torch.no_grad():\n",
    "    gradW = W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(W.size(), gradW.size()) # gradW has sample shape with W"
   ]
  },
  {
   "source": [
    "## Problem 4\n",
    "\n",
    "Fill in the following cell an implementation of the backpropagation to compute\n",
    "$$ \n",
    "\\frac{\\partial L}{ \\partial (W^T)} = \\frac{1}{10} \\sum_{i=1}^{10} \n",
    "(W\\boldsymbol{x}^{(i)} -y^{(i)}) * \\boldsymbol{x}^{(i)}\n",
    "$$ \n",
    "using explicitly the matrix-vector multiplication `mm` and elementwise multiplication `*`. Then verify that the explicitly computed backpropagation gradient coincides with the `gradW` above.\n",
    "\n",
    "Caveat: we may want to pay attention to the sizes of the vector being either `(28*28, )` or `(28*28, 1)`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    gradW1 = None # fill our code here\n",
    "    gradW1 = gradW1.view(-1,1)\n",
    "\n",
    "print(torch.norm(gradW1-gradW)) # this should be less than 1e-5 (single-precision error margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra cell"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python38364bitbaseconda97cd5720aa194725b86ca3d3cdd6281a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}